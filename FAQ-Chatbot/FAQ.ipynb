{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!','.']\n",
    "data_file = open('intents.json').read()\n",
    "intents = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        words.extend(w)\n",
    "        documents.append((w, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 documents\n"
     ]
    }
   ],
   "source": [
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "print (len(documents), \"documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(list(set(classes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(words,open('words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "output_empty = [0] * len(classes)\n",
    "for doc in documents:\n",
    "    bag = []\n",
    "    pattern_words = doc[0]\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "print(\"Training data created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.90 and logs.get('loss')<0.40):\n",
    "            print(\"\\nReached 80% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "model = Sequential()\n",
    "model.add(Dense(132, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(38, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 132)               48444     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 132)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 38)                5054      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 38)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 72)                2808      \n",
      "=================================================================\n",
      "Total params: 56,306\n",
      "Trainable params: 56,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 4.2935 - accuracy: 0.0105\n",
      "Epoch 2/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 4.2588 - accuracy: 0.0474\n",
      "Epoch 3/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 4.2551 - accuracy: 0.0368\n",
      "Epoch 4/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 4.2103 - accuracy: 0.0368\n",
      "Epoch 5/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 4.1819 - accuracy: 0.0684\n",
      "Epoch 6/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 4.1667 - accuracy: 0.0474\n",
      "Epoch 7/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 4.1363 - accuracy: 0.0632\n",
      "Epoch 8/1500\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 4.0996 - accuracy: 0.0842\n",
      "Epoch 9/1500\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 4.0413 - accuracy: 0.0947\n",
      "Epoch 10/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.9429 - accuracy: 0.1211\n",
      "Epoch 11/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.9487 - accuracy: 0.1053\n",
      "Epoch 12/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.8539 - accuracy: 0.1474\n",
      "Epoch 13/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.7828 - accuracy: 0.1579\n",
      "Epoch 14/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.6830 - accuracy: 0.1789\n",
      "Epoch 15/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 3.6692 - accuracy: 0.1579\n",
      "Epoch 16/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.5712 - accuracy: 0.1579\n",
      "Epoch 17/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.5181 - accuracy: 0.1632\n",
      "Epoch 18/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.3352 - accuracy: 0.1947\n",
      "Epoch 19/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.2497 - accuracy: 0.2158\n",
      "Epoch 20/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1893 - accuracy: 0.2579\n",
      "Epoch 21/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.1558 - accuracy: 0.2368\n",
      "Epoch 22/1500\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 3.0722 - accuracy: 0.2474\n",
      "Epoch 23/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.9095 - accuracy: 0.3211\n",
      "Epoch 24/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.8585 - accuracy: 0.3158\n",
      "Epoch 25/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.7887 - accuracy: 0.3316\n",
      "Epoch 26/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.7185 - accuracy: 0.3105\n",
      "Epoch 27/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.5314 - accuracy: 0.3632\n",
      "Epoch 28/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5498 - accuracy: 0.3684\n",
      "Epoch 29/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4114 - accuracy: 0.3684\n",
      "Epoch 30/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.3471 - accuracy: 0.4053\n",
      "Epoch 31/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.2797 - accuracy: 0.3947\n",
      "Epoch 32/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2733 - accuracy: 0.3789\n",
      "Epoch 33/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1741 - accuracy: 0.4211\n",
      "Epoch 34/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.1342 - accuracy: 0.4632\n",
      "Epoch 35/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.2533 - accuracy: 0.4053\n",
      "Epoch 36/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9486 - accuracy: 0.4632\n",
      "Epoch 37/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.9985 - accuracy: 0.4263\n",
      "Epoch 38/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.0071 - accuracy: 0.4579\n",
      "Epoch 39/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.8241 - accuracy: 0.4895\n",
      "Epoch 40/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.8264 - accuracy: 0.5053\n",
      "Epoch 41/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.8859 - accuracy: 0.4579\n",
      "Epoch 42/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.7562 - accuracy: 0.5158\n",
      "Epoch 43/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6514 - accuracy: 0.5105\n",
      "Epoch 44/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.5126 - accuracy: 0.5842\n",
      "Epoch 45/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.7411 - accuracy: 0.5316\n",
      "Epoch 46/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5121 - accuracy: 0.5684\n",
      "Epoch 47/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.6959 - accuracy: 0.5474\n",
      "Epoch 48/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.4323 - accuracy: 0.5947\n",
      "Epoch 49/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.7439 - accuracy: 0.4737\n",
      "Epoch 50/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.4441 - accuracy: 0.5895\n",
      "Epoch 51/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.5138 - accuracy: 0.5684\n",
      "Epoch 52/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2946 - accuracy: 0.6368\n",
      "Epoch 53/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2332 - accuracy: 0.6579\n",
      "Epoch 54/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4852 - accuracy: 0.5526\n",
      "Epoch 55/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.4588 - accuracy: 0.5947\n",
      "Epoch 56/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.4445 - accuracy: 0.5579\n",
      "Epoch 57/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3711 - accuracy: 0.5947\n",
      "Epoch 58/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2713 - accuracy: 0.6211\n",
      "Epoch 59/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1444 - accuracy: 0.6737\n",
      "Epoch 60/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2238 - accuracy: 0.6684\n",
      "Epoch 61/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2601 - accuracy: 0.6579\n",
      "Epoch 62/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1703 - accuracy: 0.6632\n",
      "Epoch 63/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0708 - accuracy: 0.6789\n",
      "Epoch 64/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2585 - accuracy: 0.6105\n",
      "Epoch 65/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0802 - accuracy: 0.7053\n",
      "Epoch 66/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1098 - accuracy: 0.6895\n",
      "Epoch 67/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1149 - accuracy: 0.6789\n",
      "Epoch 68/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1569 - accuracy: 0.6526\n",
      "Epoch 69/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1603 - accuracy: 0.6789\n",
      "Epoch 70/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9698 - accuracy: 0.7368\n",
      "Epoch 71/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1863 - accuracy: 0.6263\n",
      "Epoch 72/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2165 - accuracy: 0.6526\n",
      "Epoch 73/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1109 - accuracy: 0.6579\n",
      "Epoch 74/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0849 - accuracy: 0.6895\n",
      "Epoch 75/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9803 - accuracy: 0.6947\n",
      "Epoch 76/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1090 - accuracy: 0.6368\n",
      "Epoch 77/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9155 - accuracy: 0.7263\n",
      "Epoch 78/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9115 - accuracy: 0.7158\n",
      "Epoch 79/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9600 - accuracy: 0.7053\n",
      "Epoch 80/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9852 - accuracy: 0.7158\n",
      "Epoch 81/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1736 - accuracy: 0.6421\n",
      "Epoch 82/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1251 - accuracy: 0.6105\n",
      "Epoch 83/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0085 - accuracy: 0.6579\n",
      "Epoch 84/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9397 - accuracy: 0.6947\n",
      "Epoch 85/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9534 - accuracy: 0.7211\n",
      "Epoch 86/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9880 - accuracy: 0.6684\n",
      "Epoch 87/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0263 - accuracy: 0.6684\n",
      "Epoch 88/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0319 - accuracy: 0.7053\n",
      "Epoch 89/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0132 - accuracy: 0.6895\n",
      "Epoch 90/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8393 - accuracy: 0.7316\n",
      "Epoch 91/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8257 - accuracy: 0.7368\n",
      "Epoch 92/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0048 - accuracy: 0.6842\n",
      "Epoch 93/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9518 - accuracy: 0.6842\n",
      "Epoch 94/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8337 - accuracy: 0.7526\n",
      "Epoch 95/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8330 - accuracy: 0.7316\n",
      "Epoch 96/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7285 - accuracy: 0.7474\n",
      "Epoch 97/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7341 - accuracy: 0.7947\n",
      "Epoch 98/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7877 - accuracy: 0.7632\n",
      "Epoch 99/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8198 - accuracy: 0.7316\n",
      "Epoch 100/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8602 - accuracy: 0.7526\n",
      "Epoch 101/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9330 - accuracy: 0.7211\n",
      "Epoch 102/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7292 - accuracy: 0.7684\n",
      "Epoch 103/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8772 - accuracy: 0.7053\n",
      "Epoch 104/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8583 - accuracy: 0.7105\n",
      "Epoch 105/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8631 - accuracy: 0.7316\n",
      "Epoch 106/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8990 - accuracy: 0.7368\n",
      "Epoch 107/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.7947\n",
      "Epoch 108/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7360 - accuracy: 0.7684\n",
      "Epoch 109/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8197 - accuracy: 0.7474\n",
      "Epoch 110/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8712 - accuracy: 0.7263\n",
      "Epoch 111/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.9013 - accuracy: 0.7105\n",
      "Epoch 112/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7343 - accuracy: 0.7579\n",
      "Epoch 113/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7760 - accuracy: 0.7842\n",
      "Epoch 114/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8359 - accuracy: 0.6895\n",
      "Epoch 115/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.7579\n",
      "Epoch 116/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.7789\n",
      "Epoch 117/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7302 - accuracy: 0.7789\n",
      "Epoch 118/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.8053\n",
      "Epoch 119/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.8105\n",
      "Epoch 120/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8823 - accuracy: 0.6842\n",
      "Epoch 121/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7947\n",
      "Epoch 122/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8092 - accuracy: 0.7316\n",
      "Epoch 123/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7814 - accuracy: 0.7316\n",
      "Epoch 124/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.8053\n",
      "Epoch 125/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.7579\n",
      "Epoch 126/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8346 - accuracy: 0.7526\n",
      "Epoch 127/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.7684\n",
      "Epoch 128/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8858 - accuracy: 0.6842\n",
      "Epoch 129/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8453 - accuracy: 0.7474\n",
      "Epoch 130/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.7737\n",
      "Epoch 131/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8142 - accuracy: 0.7526\n",
      "Epoch 132/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7197 - accuracy: 0.7737\n",
      "Epoch 133/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.7895\n",
      "Epoch 134/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.7789\n",
      "Epoch 135/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7340 - accuracy: 0.7474\n",
      "Epoch 136/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7117 - accuracy: 0.7737\n",
      "Epoch 137/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7947\n",
      "Epoch 138/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8508 - accuracy: 0.7474\n",
      "Epoch 139/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.7895\n",
      "Epoch 140/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.7842\n",
      "Epoch 141/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7108 - accuracy: 0.7737\n",
      "Epoch 142/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.7526\n",
      "Epoch 143/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.7789\n",
      "Epoch 144/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7918 - accuracy: 0.7684\n",
      "Epoch 145/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.8316\n",
      "Epoch 146/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.8105\n",
      "Epoch 147/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.8105\n",
      "Epoch 148/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.8263\n",
      "Epoch 149/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.7895\n",
      "Epoch 150/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7450 - accuracy: 0.7632\n",
      "Epoch 151/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7584 - accuracy: 0.7421\n",
      "Epoch 152/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.7895\n",
      "Epoch 153/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7235 - accuracy: 0.7421\n",
      "Epoch 154/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.7684\n",
      "Epoch 155/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.7789\n",
      "Epoch 156/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.8053\n",
      "Epoch 157/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.7895\n",
      "Epoch 158/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.8263\n",
      "Epoch 159/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.7789\n",
      "Epoch 160/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.8316\n",
      "Epoch 161/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.7842\n",
      "Epoch 162/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.8158\n",
      "Epoch 163/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.7895\n",
      "Epoch 164/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.8105\n",
      "Epoch 165/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.7737\n",
      "Epoch 166/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7947\n",
      "Epoch 167/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7129 - accuracy: 0.7526\n",
      "Epoch 168/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.7842\n",
      "Epoch 169/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.8211\n",
      "Epoch 170/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8632\n",
      "Epoch 171/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.7947\n",
      "Epoch 172/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.8474\n",
      "Epoch 173/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.8158\n",
      "Epoch 174/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.8316\n",
      "Epoch 175/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.8158\n",
      "Epoch 176/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.7737\n",
      "Epoch 177/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.8105\n",
      "Epoch 178/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.8211\n",
      "Epoch 179/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.8000\n",
      "Epoch 180/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.8158\n",
      "Epoch 181/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.8316\n",
      "Epoch 182/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.8526\n",
      "Epoch 183/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.7737\n",
      "Epoch 184/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.7947\n",
      "Epoch 185/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.7579\n",
      "Epoch 186/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.8368\n",
      "Epoch 187/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.7684\n",
      "Epoch 188/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7102 - accuracy: 0.7684\n",
      "Epoch 189/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.7895\n",
      "Epoch 190/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7108 - accuracy: 0.7684\n",
      "Epoch 191/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.7895\n",
      "Epoch 192/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.7789\n",
      "Epoch 193/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.8368\n",
      "Epoch 194/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.8158\n",
      "Epoch 195/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8474\n",
      "Epoch 196/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8421\n",
      "Epoch 197/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7180 - accuracy: 0.7842\n",
      "Epoch 198/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.8000\n",
      "Epoch 199/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.8105\n",
      "Epoch 200/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.8105\n",
      "Epoch 201/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.8211\n",
      "Epoch 202/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.8474\n",
      "Epoch 203/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.8211\n",
      "Epoch 204/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.8368\n",
      "Epoch 205/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.8368\n",
      "Epoch 206/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7947\n",
      "Epoch 207/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.8105\n",
      "Epoch 208/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.8105\n",
      "Epoch 209/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.8053\n",
      "Epoch 210/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8474\n",
      "Epoch 211/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.7737\n",
      "Epoch 212/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8421\n",
      "Epoch 213/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.8526\n",
      "Epoch 214/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.8105\n",
      "Epoch 215/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.8053\n",
      "Epoch 216/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.8368\n",
      "Epoch 217/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.7895\n",
      "Epoch 218/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.8263\n",
      "Epoch 219/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8895\n",
      "Epoch 220/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.8000\n",
      "Epoch 221/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.8105\n",
      "Epoch 222/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.8105\n",
      "Epoch 223/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.8053\n",
      "Epoch 224/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.7684\n",
      "Epoch 225/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.7789\n",
      "Epoch 226/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7789\n",
      "Epoch 227/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.8053\n",
      "Epoch 228/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.7895\n",
      "Epoch 229/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8474\n",
      "Epoch 230/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.8263\n",
      "Epoch 231/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.8000\n",
      "Epoch 232/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8211\n",
      "Epoch 233/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.7579\n",
      "Epoch 234/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8842\n",
      "Epoch 235/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.8579\n",
      "Epoch 236/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7360 - accuracy: 0.7895\n",
      "Epoch 237/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8947\n",
      "Epoch 238/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.7842\n",
      "Epoch 239/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8474\n",
      "Epoch 240/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.8105\n",
      "Epoch 241/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8684\n",
      "Epoch 242/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8263\n",
      "Epoch 243/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8684\n",
      "Epoch 244/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.8000\n",
      "Epoch 245/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7388 - accuracy: 0.7895\n",
      "Epoch 246/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.8158\n",
      "Epoch 247/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.8421\n",
      "Epoch 248/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.8211\n",
      "Epoch 249/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.8368\n",
      "Epoch 250/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7151 - accuracy: 0.7842\n",
      "Epoch 251/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7895\n",
      "Epoch 252/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8632\n",
      "Epoch 253/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.8316\n",
      "Epoch 254/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8579\n",
      "Epoch 255/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8474\n",
      "Epoch 256/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8737\n",
      "Epoch 257/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.8526\n",
      "Epoch 258/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.8421\n",
      "Epoch 259/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.8000\n",
      "Epoch 260/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.8368\n",
      "Epoch 261/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.8421\n",
      "Epoch 262/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.8211\n",
      "Epoch 263/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.8526\n",
      "Epoch 264/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.8211\n",
      "Epoch 265/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.8000\n",
      "Epoch 266/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.8579\n",
      "Epoch 267/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.8263\n",
      "Epoch 268/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.8053\n",
      "Epoch 269/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.8263\n",
      "Epoch 270/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8737\n",
      "Epoch 271/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7947\n",
      "Epoch 272/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.8211\n",
      "Epoch 273/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.8053\n",
      "Epoch 274/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.8105\n",
      "Epoch 275/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8947\n",
      "Epoch 276/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.7789\n",
      "Epoch 277/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8632\n",
      "Epoch 278/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8632\n",
      "Epoch 279/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.8316\n",
      "Epoch 280/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.8000\n",
      "Epoch 281/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8474\n",
      "Epoch 282/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.7421\n",
      "Epoch 283/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.8158\n",
      "Epoch 284/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8684\n",
      "Epoch 285/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8211\n",
      "Epoch 286/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8474\n",
      "Epoch 287/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8526\n",
      "Epoch 288/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8421\n",
      "Epoch 289/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8263\n",
      "Epoch 290/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8474\n",
      "Epoch 291/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8053\n",
      "Epoch 292/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.8368\n",
      "Epoch 293/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.8053\n",
      "Epoch 294/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.8053\n",
      "Epoch 295/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.7842\n",
      "Epoch 296/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8474\n",
      "Epoch 297/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.8316\n",
      "Epoch 298/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8632\n",
      "Epoch 299/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.8158\n",
      "Epoch 300/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.8421\n",
      "Epoch 301/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8316\n",
      "Epoch 302/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.7789\n",
      "Epoch 303/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.8105\n",
      "Epoch 304/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8684\n",
      "Epoch 305/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.8263\n",
      "Epoch 306/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8842\n",
      "Epoch 307/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.8000\n",
      "Epoch 308/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8684\n",
      "Epoch 309/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.8421\n",
      "Epoch 310/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.7737\n",
      "Epoch 311/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8632\n",
      "Epoch 312/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8579\n",
      "Epoch 313/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8895\n",
      "Epoch 314/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8368\n",
      "Epoch 315/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.8158\n",
      "Epoch 316/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8474\n",
      "Epoch 317/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.8211\n",
      "Epoch 318/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.8474\n",
      "Epoch 319/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8263\n",
      "Epoch 320/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.8158\n",
      "Epoch 321/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.8316\n",
      "Epoch 322/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8474\n",
      "Epoch 323/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8526\n",
      "Epoch 324/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.8421\n",
      "Epoch 325/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.8263\n",
      "Epoch 326/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8421\n",
      "Epoch 327/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.8263\n",
      "Epoch 328/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8211\n",
      "Epoch 329/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8368\n",
      "Epoch 330/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.8368\n",
      "Epoch 331/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.7684\n",
      "Epoch 332/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8579\n",
      "Epoch 333/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8579\n",
      "Epoch 334/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8421\n",
      "Epoch 335/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8526\n",
      "Epoch 336/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.8158\n",
      "Epoch 337/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8632\n",
      "Epoch 338/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8105\n",
      "Epoch 339/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8684\n",
      "Epoch 340/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.8263\n",
      "Epoch 341/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8737\n",
      "Epoch 342/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8526\n",
      "Epoch 343/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8211\n",
      "Epoch 344/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8947\n",
      "Epoch 345/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.8158\n",
      "Epoch 346/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8632\n",
      "Epoch 347/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.8263\n",
      "Epoch 348/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.8316\n",
      "Epoch 349/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8684\n",
      "Epoch 350/1500\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.7632\n",
      "Epoch 351/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.7632\n",
      "Epoch 352/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8474\n",
      "Epoch 353/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.8526\n",
      "Epoch 354/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.8474\n",
      "Epoch 355/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.8211\n",
      "Epoch 356/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8474\n",
      "Epoch 357/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8895\n",
      "Epoch 358/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.7684\n",
      "Epoch 359/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.8211\n",
      "Epoch 360/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.8105\n",
      "Epoch 361/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.8421\n",
      "Epoch 362/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.8316\n",
      "Epoch 363/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8632\n",
      "Epoch 364/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.8158\n",
      "Epoch 365/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8895\n",
      "Epoch 366/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.8000\n",
      "Epoch 367/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8789\n",
      "Epoch 368/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.8368\n",
      "Epoch 369/1500\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.8105\n",
      "Epoch 370/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.8316\n",
      "Epoch 371/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8105\n",
      "Epoch 372/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.8000\n",
      "Epoch 373/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8632\n",
      "Epoch 374/1500\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.8316\n",
      "Epoch 375/1500\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.3514 - accuracy: 0.9143\n",
      "Reached 80% accuracy so cancelling training!\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.9053\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs=1500, batch_size=5, verbose=1,callbacks=[callbacks])\n",
    "model.save('chatbot.h5', hist)\n",
    "\n",
    "print(\"model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAA9/klEQVR4nO3deXhcZdn48e+dbbJM9q1pkjbd95W2tLQsxQqlRUFBRAFf0Z+AgtsrKvgqCqLihqzKIggqgiCLLK1CWVug0L1N9y1tkjb7vm/P749zZjKTTNqkzWSSzP25rlw5c86ZmXtOm3PPs4sxBqWUUsErJNABKKWUCixNBEopFeQ0ESilVJDTRKCUUkFOE4FSSgU5TQRKKRXkNBEo1Usi8oSI3NnLc/NEZNnpvo5SA0ETgVJKBTlNBEopFeQ0Eahhxa6S+b6IbBeRehF5TETSRWS1iNSKyBoRSfQ4/9MislNEqkTkHRGZ4nFsjohstp/3TyCyy3tdLCJb7ed+ICIzTzHmr4nIARGpEJGXRWSkvV9E5A8iUiIi1fZnmm4fWyEiu+zYCkXk5lO6YEqhiUANT5cBnwQmAp8CVgM/AlKw/s9/C0BEJgJPA98BUoFVwCsiEiEiEcBLwN+AJOA5+3WxnzsXeBy4HkgGHgZeFhFHXwIVkfOBXwFXABnAEeAZ+/AFwDn250gAPg+U28ceA643xsQC04G3+vK+SnnSRKCGo/uNMcXGmEJgLfCRMWaLMaYZeBGYY5/3eeA1Y8wbxphW4HdAFHAWsBAIB+4xxrQaY/4FbPB4j68BDxtjPjLGtBtjngSa7ef1xVXA48aYzXZ8twKLRCQHaAVigcmAGGN2G2OO289rBaaKSJwxptIYs7mP76uUmyYCNRwVe2w3+njstLdHYn0DB8AY0wHkA5n2sULjPSvjEY/t0cD37GqhKhGpArLt5/VF1xjqsL71Zxpj3gIeAB4EikXkERGJs0+9DFgBHBGRd0VkUR/fVyk3TQQqmB3DuqEDVp081s28EDgOZNr7XEZ5bOcDvzDGJHj8RBtjnj7NGGKwqpoKAYwx9xljzgCmYVURfd/ev8EYcwmQhlWF9Wwf31cpN00EKpg9C6wUkU+ISDjwPazqnQ+AD4E24FsiEiYinwUWeDz3UeAGETnTbtSNEZGVIhLbxxj+AVwrIrPt9oVfYlVl5YnIfPv1w4F6oAlot9swrhKReLtKqwZoP43roIKcJgIVtIwxe4GrgfuBMqyG5U8ZY1qMMS3AZ4EvA5VY7QkveDx3I1Y7wQP28QP2uX2N4U3gJ8DzWKWQccCV9uE4rIRTiVV9VI7VjgFwDZAnIjXADfbnUOqUiC5Mo5RSwU1LBEopFeQ0ESilVJDTRKCUUkFOE4FSSgW5sEAH0FcpKSkmJycn0GEopdSQsmnTpjJjTKqvY0MuEeTk5LBx48ZAh6GUUkOKiBzp6ZhWDSmlVJDTRKCUUkFOE4FSSgW5IddG4EtraysFBQU0NTUFOhS/i4yMJCsri/Dw8ECHopQaJoZFIigoKCA2NpacnBy8J4scXowxlJeXU1BQwJgxYwIdjlJqmBgWVUNNTU0kJycP6yQAICIkJycHRclHKTVwhkUiAIZ9EnAJls+plBo4wyYRnExzazvHqhrp0NlWlVLKS/AkgrYOyuqaqWpo7ffXrqqq4o9//GOfn7dixQqqqqr6PR6llOqLoEkEsZFhRIaHcqyqkerGln597Z4SQXv7iReNWrVqFQkJCf0ai1JK9VXQJAIRITMhChEoqGiko6P/qohuueUWDh48yOzZs5k/fz5Lly7li1/8IjNmzADg0ksv5YwzzmDatGk88sgj7ufl5ORQVlZGXl4eU6ZM4Wtf+xrTpk3jggsuoLGxsd/iU0qpExkW3Uc93f7KTnYdq+nxeHuHoam1HUd4KGEhvWt4nToyjp9+alqPx++66y5yc3PZunUr77zzDitXriQ3N9fdxfPxxx8nKSmJxsZG5s+fz2WXXUZycrLXa+zfv5+nn36aRx99lCuuuILnn3+eq6/W1QeVUv4XNCUCl9AQQURobe/w23ssWLDAq5//fffdx6xZs1i4cCH5+fns37+/23PGjBnD7NmzATjjjDPIy8vzW3xKKeVp2JUITvTN3aWyoYX8igbS4iJJj3X0e5fMmJgY9/Y777zDmjVr+PDDD4mOjua8887zOQ7A4XC4t0NDQ7VqSCk1YIKuRACQEBVOYnQEJTVN1DSefi+i2NhYamtrfR6rrq4mMTGR6Oho9uzZw/r160/7/ZRSqj8NuxJBb4gIWYlRNLa0U1TTTFxU+GmVCpKTk1m8eDHTp08nKiqK9PR097Hly5fz0EMPMXPmTCZNmsTChQv74yMopVS/ETPEBljNmzfPdF2YZvfu3UyZMqXPr1Xd2MKR8gZGJUWTEB3RXyH63al+XqVU8BKRTcaYeb6OBWXVkEtcZDgRYSGU1/XvuAKllBpKgjoRiAiJ0RHUt7T5tReRUkoNZsMmEZxqFVdspNVMUtfc1p/h+M1Qq8pTSg1+fk8EIhIqIltE5FUfx0RE7hORAyKyXUTmnsp7REZGUl5efko3yajwUMJCQqhrGvyJwLUeQWRkZKBDUUoNIwPRa+jbwG4gzsexi4AJ9s+ZwJ/s332SlZVFQUEBpaWlpxRgeV0zJR2GurjBf4N1rVCmlFL9xa+JQESygJXAL4D/9XHKJcBfjfVVfr2IJIhIhjHmeF/eJzw8/LRW7Prlqt088UEeu26/kLDQYVNbppRSveLvu949wA+AnlpiM4F8j8cF9j4vInKdiGwUkY2n+q3/RCakOWlp6+BoRUO/v7ZSSg12fksEInIxUGKM2XSi03zs61bRb4x5xBgzzxgzLzU1td9idJmYHgvAH9bs195DSqmg488SwWLg0yKSBzwDnC8if+9yTgGQ7fE4Czjmx5h8Gp/mBOCVbcf4T27RQL+9UkoFlN8SgTHmVmNMljEmB7gSeMsY03Ve5ZeBL9m9hxYC1X1tH+gPMY4wnr1+EQB7inqewloppYajAZ9rSERuADDGPASsAlYAB4AG4NqBjsdlwZgkJqQ52VtUF6gQlFIqIAYkERhj3gHesbcf8thvgBsHIobemDgilu0FVYEOQymlBpT2lfQwKT2W/IpG6ofIKGOllOoPmgg8TBtpjXnbXlAd4EiUUmrgaCLwcMboRAA2HakIcCRKKTVwNBF4SIiOYEKak41HKgMdilJKDRhNBF3My0lk85FKneVTKRU0NBF0MXlEHDVNbZTUNgc6FKWUGhCaCLqYYI8yPlCi4wmUUsFBE0EX49OtRLC/uDbAkSil1MDQRNBFqtNBfFQ4+7VEoJQKEpoIuhARpmfG8er24+QW6ngCpdTwp4nAh19+ZgbGGP7yfl6gQ1FKKb/TRODD6OQYZmYlsL9E2wmUUsOfJoIeTEh3sr+4jo4OHU+glBreNBH0YGJ6LI2t7RRWNQY6FKWU8itNBD2YaHcj3afdSJVSw5w/1yyOFJGPRWSbiOwUkdt9nHOeiFSLyFb75zZ/xdNXk0fEEREawocHywMdilJK+ZU/SwTNwPnGmFnAbGC5vRxlV2uNMbPtnzv8GE+fxDjCOGt8Mq/vKtZ5h5RSw5o/1yw2xhjXqKxw+2dI3VGXTUnnaEUDh8vqAx2KUkr5jV/bCEQkVES2AiXAG8aYj3yctsiuPlotItP8GU9fueYd0gZjpdRw5tdEYIxpN8bMBrKABSIyvcspm4HRdvXR/cBLvl5HRK4TkY0isrG0tNSfIXtJiXUAUF7XMmDvqZRSA21Aeg0ZY6qwFq9f3mV/jav6yBizCggXkRQfz3/EGDPPGDMvNTV1ACK2pDitRFBWp1NSK6WGL3/2GkoVkQR7OwpYBuzpcs4IERF7e4Edz6DpphMXGUZEaAilmgiUUsNYmB9fOwN4UkRCsW7wzxpjXhWRGwCMMQ8BlwNfF5E2oBG40gyiLjoiQoozgrJarRpSSg1ffksExpjtwBwf+x/y2H4AeMBfMfSHlFiHVg0ppYY1HVl8EilOTQRKqeFNE8FJpDgjNBEopYY1TQQnkRrroLyuhXadhVQpNUxpIjiJsSlO2joMh0p16Uql1PCkieAkpmXGAbDzWE2AI1FKKf/QRHAS41KdRISFsPOYrl+slBqeNBGcRHhoCFNGxJJbqCUCpdTwpImgF+aMSmRLfiVNre2BDkUppfqdJoJeOHtCCk2tHWw+UhnoUJRSqt9pIuiFhWOTCQ8V3tk3cDOfKqXUQNFE0AsxjjDOm5TGPzfkU9vUGuhwlFKqX2ki6KWblo6nurGVl7YUBjoUpZTqV5oIemlWdgKpsQ625FcFOhSllOpXmgj6YEZmPDu1G6lSapjRRNAH00fGsb+klsYW7UaqlBo+NBH0wbTMeDoM7CnSUoFSavjw51KVkSLysYhsE5GdInK7j3NERO4TkQMisl1E5vornv6QkxwDQGFVY4AjUUqp/uPPpSqbgfONMXUiEg6sE5HVxpj1HudcBEywf84E/mT/HpTSYq3F7EtqdH0CpdTw4bcSgbG45m4Ot3+6Tup/CfBX+9z1QIKIZPgrptOVEB1ORGgIxbVNgQ5FKaX6jV/bCEQkVES2AiXAG8aYj7qckgnkezwusPd1fZ3rRGSjiGwsLQ3c6F4RIS3OoSUCpdSw4tdEYIxpN8bMBrKABSIyvcsp4utpPl7nEWPMPGPMvNTUVD9E2nvpcZEU12iJQCk1fAxIryFjTBXwDrC8y6ECINvjcRZwbCBiOlVpsQ5NBEqpYcWfvYZSRSTB3o4ClgF7upz2MvAlu/fQQqDaGHPcXzH1h/S4SEpqtWpIKTV8+LPXUAbwpIiEYiWcZ40xr4rIDQDGmIeAVcAK4ADQAFzrx3j6RVqcg9qmNmqbWomNDA90OEopddr8lgiMMduBOT72P+SxbYAb/RWDP8zJTgRg3f4yLpoxaDs4KaVUr+nI4j6an5NIUkwEq3OLAh2KUkr1C00EfRQWGsKyKWm8s7eEjo5uHZyUUmrI0URwCs4ck0xNUxv7S+pOfrJSSg1ymghOwfycJAA25FUEOBKllDp9mghOQXZSFGmxDjZqIlBKDQOaCE6BiDA/J4kNeZWBDkUppU6bJoJTNC8nkcKqRo7plNRKqSFOE8EpcrUTbDyipQKl1NCmieAUTR4RS3iosPNYdaBDUUqp06KJ4BSFhYaQ4nRQXtcS6FCUUuq0aCI4DcnOCMrqdAI6pdTQpongNGiJQCk1HGgiOA3JMQ4tESilhjxNBKchJTaC8roWrElUlVJqaNJEcBpSYhy0tHdQ09QW6FCUUuqUaSI4DSmxEQAcr9ZBZUqpocufS1Vmi8jbIrJbRHaKyLd9nHOeiFSLyFb75zZ/xeMPyTEOAJbfs5ZSXb5SKTVE+XOpyjbge8aYzSISC2wSkTeMMbu6nLfWGHOxH+Pwm5EJUe7tg6V1pMY6AhiNUkqdGr+VCIwxx40xm+3tWmA3kOmv9wuE8WlO7r1yNgCFlVo9pJQamgakjUBEcrDWL/7Ix+FFIrJNRFaLyLQenn+diGwUkY2lpaX+DLXPLpw2AkAnn1NKDVl+TwQi4gSeB75jjKnpcngzMNoYMwu4H3jJ12sYYx4xxswzxsxLTU31a7x9FRkeSoozgmPaYKyUGqL8mghEJBwrCTxljHmh63FjTI0xps7eXgWEi0iKP2Pyh5EJURRo1ZBSaojyZ68hAR4Ddhtj7u7hnBH2eYjIAjuecn/F5C+ZCVFaNaSUGrJ6lQhE5NsiEieWx0Rks4hccJKnLQauAc736B66QkRuEJEb7HMuB3JFZBtwH3ClGYLDdLMSo8ivbKSlrSPQoSilVJ/1tvvoV4wx94rIhUAqcC3wF+D1np5gjFkHyIle1BjzAPBAL2MYtOaOSuTRtYfZUVjFGaOTAh2OUkr1SW+rhlw39BXAX4wx2zjJTT6YLBhj3fzXH9LF7JVSQ09vE8EmEXkdKxH81x4gpvUgtmSng0npsaw/NOSaN5RSqteJ4KvALcB8Y0wDEI5VPaRsC8cmselIJa3tmh+VUkNLbxPBImCvMaZKRK4GfgzoYr0eFo5NpqGlnR2FelmUUkNLbxPBn4AGEZkF/AA4AvzVb1ENQa52gsfWHaa5rT3A0SilVO/1NhG02d06LwHuNcbcC8T6L6yhJ9np4OqFo3ht+3Ge3ZBPQWUDe4q6DqRWSqnBp7eJoFZEbsUaF/CaiIRitRMoDz+/ZDoJ0eHsOl7Lkl+/zfJ71gY6JKWUOqneJoLPA81Y4wmKsGYR/a3fohqiRIQJaU4OlNQGOhSllOq1XiUC++b/FBAvIhcDTcYYbSPwYXxaLHuLNBEopYaO3k4xcQXwMfA54ArgIxG53J+BDVUT051eaxi3dwy5GTOUUkGmt1NM/B/WGIISABFJBdYA//JXYEPVjMx4r8f1LW3ERWpzilJq8OptG0GIKwnYyvvw3KByxuhEr8d1HqUDpZQajHp7M/+PiPxXRL4sIl8GXgNW+S+soUtE+Pml092P65o1ESilBrdeVQ0ZY74vIpdhTS0twCPGmBf9GtkQds3C0WQnRvHlv2ygVksESqlBrrdtBBhjnsdabUz1QmykdWm1RKCUGuxOmAhEpBbw1e1FAGOMifNLVMOA02E1ENdrIlBKDXInbCMwxsQaY+J8/MSeLAmISLaIvC0iu0Vkp4h828c5IiL3icgBEdkuInNP9wMNFk5XiUCrhpRSg5w/e/60Ad8zxkwBFgI3isjULudcBEywf67DmtxuWHA6rERQ09RKUXVTgKNRSqme+S0RGGOOG2M229u1wG6sqSk8XQL81VjWAwkikuGvmAZSTEQoAHe+tpuFv3qTzUcrAxyRUkr5NiBjAUQkB5gDfNTlUCaQ7/G4gO7JAhG5TkQ2isjG0tJSv8XZn8JCvS/t4dL6AEWilFIn5vdEICJOrN5G3zHGdJ2X2de6x90ap40xjxhj5hlj5qWmpvojTL8rq2sOdAhKKeWTXxOBiIRjJYGnjDEv+DilAMj2eJwFHPNnTAMpNEQYlRRNZHiIJgKl1KDlt0QgIgI8Buw2xtzdw2kvA1+yew8tBKqNMcf9FdNA23rbJ3n9u+eQ4nRQVtcS6HCUUsqnXg8oOwWLsRay2SEiW+19PwJGARhjHsKapmIFcABoAK71YzwDLtaebM5KBM3UNrUSGiJER/jzsiulVN/47Y5kjFmH7zYAz3MMcKO/YhgsUpwOCiobmPGz1xmbEsNbN58X6JCUUspNZxAdAKmxEewrtharOVSmvYeUUoOLJoIBkOJ04Lk+TYcuVqOUGkQ0EQyAjPgor8el2oNIKTWIaKvlAPjMnExSYx0UVTfyk3/vpKCygfS4yECHpZRSgJYIBkRURCifnJrOonHJABRUNgY4IqWU6qSJYABlJkQDkF/R0O1YTVPrQIejlFKAJoIBFRURSnqcg8NlDTy7MZ+L718LQG5hNbNvf50DJXUBjlApFYy0jWCAjUt1crC0jqiIEHILa2hqbSe/ooEOAwWVDYxPcwY6RKVUkNFEMMDGpzl5cUshmYlWT6Lb/p1LTaO1eI0ua6mUCgRNBANsXKqT2qY2DhRb1UDPbixwH9PVzJRSgaBtBANsXKpV9bPXHmnsSUsESqlA0EQwwHJSons8VqslAqVUAGgiGGAj4iIJ6WEqPi0RKKUCQRPBAAsLDSHZ6fB5TNsIlFKBoIkgAJwO3230WiJQSgWCJoIAiI4I9bm/VhOBUioA/LlU5eMiUiIiuT0cP09EqkVkq/1zm79iGWxielihrE6nmVBKBYA/SwRPAMtPcs5aY8xs++cOP8YyqMQ4fJcINh+t4o/vHBjgaJRSwc5vicAY8x5Q4a/XH8ruuGQ6K2dk8OOVU5g7KsHr2G/+sxdjDB8frqBdF7BRSg2AQLcRLBKRbSKyWkSm9XSSiFwnIhtFZGNpaelAxucX2UnRPHjVXP7f2WP54fLJ3Y7vPFbDFQ9/yM3PbQtAdEqpYBPIRLAZGG2MmQXcD7zU04nGmEeMMfOMMfNSU1MHKr4BERsZ3m1fQaU1TfWLWwpZs6t4oENSSgWZgCUCY0yNMabO3l4FhItISqDiCZS4KKvhONajS+nhMisRRIaH8N1/bqWtvSMgsSmlgkPAEoGIjBARsbcX2LGUByqeQMmIj+LK+dk89/VF/PbymQAcKa8H4OYLJlHb3OZzXiKllOov/uw++jTwITBJRApE5KsicoOI3GCfcjmQKyLbgPuAK40xQdc6Ghoi3HXZTCaPiCMnJQaAI+VWieC8SVY12OajVYEKTykVBPw2DbUx5gsnOf4A8IC/3n8oSoy22guOlNcTERbCuFQnKU4HW45Ucs3C0QGOTik1XAW615DykBgdAcCx6ibio8IREWZlxbPreE2AI1NKDWeaCAaR+Kjwbtvj050cKq3XBmOllN9oIhhEwkJDiIu0autcvyekxdLS3sGRioZAhqaUGsY0EQwySTFW9ZCrRDAx3VrRbL+9tKVSSvU3TQSDzKQRsQDE2YnAtbTl/uJa2jsM5XXNALS2dxCEnayUUn6giWCQWTLeGlNX1WDNRBrjCGNEXCR55Q186+ktnHHnGmqaWpn/izW8tuN4IENVSg0TmggGmcV2IqjxmJI6OymKXcdr3Df+Dw+WU9XQyu4eehNpSUEp1ReaCAaZMSkx3HrRZH57+Sz3vuzEaK+b/gcHygAoq23p9vyfv7qLC/7wnv8DVUoNG34bUKZOjYhw/bnjvPZlJUV7HIcPDlozcZTa7QUux6oaeWzdYQAq6lvcDc9KKXUiWiIYAkbZiSA9zsH4VCf7S6weRKW1ViJoaetg9/Ea1uzunKn0YGn3XkYltU2suHct+3TuIqWUB00EQ0BGfCRgjTyeaPcqAiizSwTXPvExF927lj+8sc997GBJ90Sw/lAFu47X8OOXfK4eqpQKUpoIhgBXl9LvLJvA5HTvRJBbWM37B6yqosqGViJCQ4gIC/FZImhubQfg48MV2qCslHLTRDAEpDgd5N21kuXTM7xKBK3thi88up6IsBBGxFmlhmRnBGNTYthTVEtFfQs/fmkHTXYCKKvrbFwuqGwc2A+hlBq0NBEMMZM9EgFAbVMbD35xLmNTrSmsE6IjWDYlnbX7y/jcQx/w9/VHeW271e203KNx2TXVtVJKaSIYYrITo4kKD2Wk3W5w+6en8cmp6SQ7HQAkxYRz49LxJEaHc7DUWuAmxP5XLq9vISLUenDYXvxGKaX81n1URB4HLgZKjDHTfRwX4F5gBdAAfNkYs9lf8QwXISHCj1ZMZlyqk5yUGEYmRAGQbHcVTYiOICoilCkZce5upnVNbYDVpjAlI5a9xbUcKdNEoJSy+LNE8ASw/ATHLwIm2D/XAX/yYyzDyjWLcjhrfIo7CQCkOK1E4FrcxjVHEVglAbDaCFJjHYxOiiHPrhoqrW3m+r9t5IuPrqe6oXM0s1IqePgtERhj3gMqTnDKJcBfjWU9kCAiGf6KZ7hzVw3Zi9uMT/NIBHWuRNBMcoyD0cnR5NlVQ/e9uZ//7izmg4Pl/PjfuTS1tvPE+4dpadP1D5QKFoEcWZwJ5Hs8LrD3dZtJTUSuwyo1MGrUqAEJbqjxrBoCGJXcORq5vL6Zjg5DRX0LKbERpMc5eHNPCfkVDTy3KZ/PnZFFQ2s7uYXVvLilkJ+9sovapja++YkJAfksSqmBFcjGYvGxz2fndmPMI8aYecaYeampqX4Oa2hylQgSY6yqoUle4w1aeGZDPu0dhikZcczLSaK9w/C957bR1NrB184ZS1qsg9LaZto6rH+Cd/eVDvyHUEoFRCATQQGQ7fE4CzgWoFiGvOmZcVy7OIdzJ6YBMDIhim23XcBF00dQWtvM3W/s5cwxSayckcHc0YmANbDs3ImpTEyPJTXWQV1zGwWVVtvB9sJqXR5TqSARyETwMvAlsSwEqo0xOsH+KXKEhfLTT03zmmguPjqcZGcEh8vqKatr4ctn5SAiOB1hLBybRERYCD+5eCoAabFWd9Tdx615iFraOiis8h50ZozhzF+u4S/vHx6gT6WUGgj+7D76NHAekCIiBcBPgXAAY8xDwCqsrqMHsLqPXuuvWIJZun2DDwsRlk5Oc+9/7H/mExYqOMJCAUiNtaqWPKe7zitvYHRyjPvxkfIGimuauf2VXVy7eAwA+RUNxEWGE2/3VsotrCY2MszreUqpwc1vicAY84WTHDfAjf56f2W5ZtFowsNCGJUUTWR4qHt/jMP7nz7VbmMorW1mXGoMB0vrOVpeD3S2yWw+WglAVmIUhVWNxEeFc/Zv3mbx+GSe+n8Lqaxv4eL71zEyPpIPbv1Et1jK6prZUVjN0klp3Y49+t4hFo1LZnpmfH98bKVUH+h6BMNcQnQEN3RZ38AXV4kAYOrIeAqrGt1jDVw2HbESQUFlI4vveos0+zl7i6zqpEfWHgK85zTydPWfP2JPUS1771zuLokAtLV38ItVuwHIu2tlbz+aUqqf6BQTCoCkmAhCQ6yOXKlOa9DZ3qJa9yyl7R2Gd/Z69yQqsddDGJ0cgzGGl7dabf3x0eEYY6is904Ie+yE4RrpDLi7tbr4mjUV4KZ/bPaaZlsp1X80ESgAQkPEawbTMSkxrDtQxi/tb+rv7S+lsKrRPV4hNER4++bzWDFjBFUNLeQW1lBY1cjI+EjK65p5/P085vz8DfIruk9uV+uRCO55cz9Lf/eO+/HGvAraO7r3In51+3HufXN/f35kpZRNE4Fye/Ir8zl7QgpLxqfww4smA9ZiNmDV4ac4HVy5wOrxOzIhkjEpMSRER1DV0Mq7+0oA+MKCUXQY+P3rewHYXlDd7X2+/69tPG4vqbnrWA31Le3uYz98fgfjfrRK10tQagBpIlBu49Ni+dtXz2RWdgJjUmL48lk5HCyt46ND5XxwsJyvnzfOXWqItOv4E6PDqWpsZXtBNWNSYtzrJTTYN/fcY90TwYa8Su54dReHy+q7rbvs4tl1tcNHCcEYw7w71/Bnu11CKXXqNBGoHo1Lc9LQ0s7D7x0iJiKUq84cRaJdNeQIt/7rJERF0N5hWH+onGkj49wNyC47fJQIXF7eeoyy2s5EEBfZ2XfB1QANUNfSWZXU3GYlmNK6Zsrqmrnztd1er9nW3nHC91RKdaeJQPVonL3YzVt7Sjh3UiqR4aEkRNmJwC4RJNjjB2qa2piRGU+aXWIAuGT2SHYUVtPRYdyrpHk6VFZHqUcimJwR597eW2wlgoaWNq82Bdf5+4utRmXX+gpgNWhffP86PvXAOrbYXV2VpaSmyWfbC1hjQVwjylVw0kSgeuQ5g+knp6YDEB5q9SxKj7O++bsmuQOYnhnvHo8wIc3JkvEpVDe2suCXa3jo3YPdXn9bfhUtHtNYuJ4LVolg05FKpt72X/7x0RH3/hJ3IrAShWsgG1iD4Vw9k/699Rj/3lro83O9vbekW2Lyd5tEXlk9JTVNfn2PnpTUNLHgl29yzxrfva7O/s3bLPn12+7HTa3t1De3+TxXDU+aCFSPUp0Obr5gIj+/ZBqXzMoEYH5OEt+/cBJ3XjoD6CwRAMwZlUBEWAj/vnExL964mPk5SYA1ruCeNd49fkYlRXcbp9DsMfX17uM1rNtfBsCDb3cmkec2FnDub9/mzT1W47Tn/XtLfpV7+4kP8vj2M1u73fD3Fddy7V828NN/73TvO1Rax+Sf/MdrVHVfVTW0cM5v3uaW57ez8r61bDla6VXauejetSz45ZvUNg38mg9FdgJ6y75mnnzNJ7Xi3rVM++l//R6XGjw0EageiQg3nT+BaxblEGKPMQgJEW5cOt49p1GiRyKIjrDq+GdlJ+B0hDHaYyrsrs6wJ77zNDXDamg+Z2IqB0rq2Hik+3IWT398lCPlDay1k0RFfbO7ymPLkUpSnA6cHqOmb3l+u1fDc02jdSPe4PHae4pqaW7r4P0DZSe6HD6V1TWz61gNG/IqOVrRwDMb8tl5rIbP/PEDfvTiDvd5jXZCeuqjo31+j9PlSrBhod3/3A/7WKnukL2vP0tJpbXNfHz4RMuT9Kyjw3DX6j0+Yx3MXt9ZxB/fORDoMHpFE4E6LYl21dA8Hzd2EWtZTV/m5XQ//1ufmMCz1y/imoWj6TCwdn+Ze9yCp8yEKK5ZONrdVbXc7nm0Jb+KOaMSSIvrrGJ6aesxHnirszTiGryWV1bPB/aNv9j+xryjsHsjszGGfcW11HWpKqluaOXGpzYz7841rLhvLYU+6thLPEoEUfb0Hkd9jKvo6kBJHXe+usurt1R7h6GxpXs7S2+4Vp4LD+k+8/tuj0b5rjd+z/hP12PrDvOlxz86peRSWNXIQ+8eZHXu0JmTcmt+Fdf9bRO/+c9en+1jg40mAnVakp0OHv3SPB6/dr7P49edM447L7WWrPbsFbRyRgYLxiQRExHKtJFxXDwzg7DQEBaMSWJmVud8QxfNGOHevv8Lc4iLDOPBq+by80unc+5Eax6kktpmaptaOVxWz8zMeMLsG56r1JJX1sDD7x7k4vvXuldm6zDwxT9/RM4tr3H7K7sA34ng9ld2ccEf3uOOV6yqpNqmVmqaWnlzTzGv7ei8MeUe66xWuvuKWZw1LpmWtg425FXQ2t7hLhEUV5+8neCmf2zmz+sOc8Qjadz6wnam3PYfjDG0dxje3tO9neNXq3fzmT++3+31quxSUFho90Swx6M6rLHL6x0qPfE38B0F1V7VXydSUd9MU2uHu1txX7i6GFf0MHWJLxvzKsgLYAnicFnnCPnKBu+4Nx2pPK1qSH/QuYbUaXM1JPckx56JNDEmghq7B1B8VDjPXr+I1vYOwrtUWaTHRTIpPZbQEOE7yyby9/VWdcqyKelcPDMDEXsqjNjOifJcN7GpI+P41+YCAH5/xSxe31nE0x/n8+GhcgByC3v+AzxUWm/f6NtIjonAERbCq9utm/3q3CIump7BtU9sYFZWPBdMG+H13PcPlJEYHc4Zo5P45NR0NuRV8sHBo3zuoQ/59WUz3OcV9aLBuNWut6+ob2FMinXtnt1ofaZj1U3kFlZz/d82MSIuknU/XOqu8nn4XWtMhTEGEWF/cS0bj1S6G367XmeA4x6JqbKh1T0+BKxeXYvGJbsfG2N4bcdxJo+I5VBpPdf9bRNjU2J46+bzevwsTa3t3PvmfvLKrKRW1djabcLDkympsRJBeZcpS2qaWvlvbhGXzc1yV126XP7Qh4jA4V/1bu6q3MJqyutb3F8uTpfnNCqV9a1kxHeuL/6Tl3KJiwrjmesW9ct79QdNBMrvxqVZN7NrFo529/t33cx93ZwAXvnmEiLCvI9Fhoe4nwfW6GaAgsoGdzvBtJHxNLdaN9LsxCimenRJnTwi1t2rCODHK6fw1p4SPjhYTohYpYTtBdVc9eePWDYljTsumU5ZXTPnTEzlvX2l3PqCVee/raCaUV2m2T5e3cTlZ2Txu8/NArwn8dtnd3V1hIVQVN1ESW2Te/0HF2MM5//+XZZNSXNfk2IfSWPP8Rp3j6mimibWH6qgpLaJqSM7P2dNUxvxUeGsvH8dLW0dfOO8ce7X++eGo3x+fudyr54318r6FpwRnbeEriWC9YcquOkfW7z2HTrJt+5H3zvEn97pbOyvbmglM8G6KT67MZ/9xbX838qpJ3wNV4mgayJ4+N2DPPj2QaIiQrl45kj3flf1X19qoS6+fx3gPenhf3KLiHGEcvaEvieHuubOkk9Vo3fc1Y2tFFY1uhP2YKBVQ8rvMuKj2PKTT/LVJWPc33BPpmsSALr90YyIiyQ2Mow9RbXsPFZDcoy1HvMdl0wjOymK7KRoptnTWn9mTiYX2CWXFKeDv3/1TL66ZAzLplj7XKWW13cWAbBmdwnb7F5INy0dT0RYiNe3+TW7ilkyPoW3Pb4NTx7RuTyo58C6MvtGNjE9lvL6Fhb84k3yKxooqW1ia34V7R2GzUcrOVxWz6NrD+OwP/uxqkbO/9073LtmP5H2AL49RbUc9LhBX/3YR/zvs9tYfs/abu/XYjcSu6qY9hXX8cPnd7CjoNo9IWB5XTOxdpVdVUOrVzVG13miqhtP3uOpqqGFO1/dRU1TqzUR4TbvRQerGlt4c3cxc3/+Bj/413YeXXuYmhP0pPrXpgJ+919rupKKeu9qKNeyqq9u8247OFDie+LCnni2WzTYgxcLqxq54e+buOaxj/v0Wi6e3W+rGlrJr2hg2d3vUljVSE1TK9WNrRTXdK9WC9SqgFoiUAPCNSJ59bfP7nFgU1+JCFNGxLH7eA1F1U3MHZ2IiHDBtBHuqps52Qk89f/OZMGYJFbZdfqNLW0smZACwIR0a6xEeGgImQlRrMotcr/+piOVhIcKs7LjmZUVz4a8SpaMT2HdgTIaW9sZlxrjnnIDYHZ2gnvbMxG4ZlSdkOZ0t0P8e2shf153mKqGVi6dPZL/7ix2n19QafVyem9/GYfK6vmDR///vUW1HCmvZ/H4ZN4/YFV3ZSZY60O4SjX5FQ08tq5zFbmudeWfemAdSTERbP7JJ6mob2FcqpOt+VVUNrQQ4+isGnLF4VJa272EEtalSuYrT2xg89EqEqLDOVRaz/4uN+Wyuha+9bR3qeKDA+Usn+5d1QbQ2NLOzc9tcz8u79JGUFVvJZB395VijKG5rYPnNuaDj2/Zu47VEBkewtjUzrExzW3tRISGeH3OvLIGpo6Mc8+FBZzSN3fPzgWVDS08+UEeB0rqeGFTgfvY7qIaRsRb/39+9vJOjDE8+eERXv3mEve6HMYYimqavKqW/MGviUBElgP3AqHAn40xd3U5fh7wb8B11V8wxtzhz5hUYHkujtNbb3z3HK+pqj1Nzojlrx9aA87+94JJ3Y6LCIvHWzf9cfZNwHOSO9eNISMhEkdYiNcN+V+bC5iaEYcjLNRdlXPORCsRAJw5NpmoiM7P47mojucIa9c31KzEzj/m373eeXN/aesxHGEhfPP88dz/1gF3Fch7+7yn/Qar3v5IWQOfnZtJbmEN1Y2trPnfc3l3Xykj4iO59MH3+euHR7zGDPjqdllR34IxhvK6FhaPT2FrfhVVDS3urrfTM+PIr2ikvcO4pyf31b4RIsKBklre3lNKVmIUm49WAXDPmv20dRiuXjiK1TuK3J/p3b3dP9Pa/aU+E8Er271LE+V2zK6bcrGdmBpb2ymvb+GJ9/N44O0DpDitLx1hIeI+/zv/3EKMI4ypGXF8/bxxpMY6mPTj//CVxWNYMKazB9t7+0sZn+b0GpleWtfcrSrvZOqarXam8voWqhpa3aUpkc4qqz3Ha1k6KQ1jDE98kOcVw8PvHaLNbj97edsxNv54GSlOh4936h9+qxoSkVDgQeAiYCrwBRHxVRm41hgz2/7RJKC6mZAey5ljk30em+RRHfOJyd1XPvPkq1oqMyGKP141l7uvmO0eAOdS1dDKLPtb/jeWjiPF6WDlzJFEhocQGR7CRV1uXp5JzrPba5PdZnHupDScjjA+OyfTfez6c8cCcPunp/HdZRO9xkAApDgj3N+6s5OiyC2soba5jTEpMbz6zSWs/vbZREWEsnz6CLLtRNN1PERPPXVqm9toae9grD2VSGVDq7v0Mn1kPNWNrYz70Spy7VJMcU0zqbEOXrlpifs1Wto7uP2VXfxi1W5ufm4bU+w2mbYOw9xRCdx56Qx3aRDgzT2didalp95JrvUt3O/V1uH+Nv3a9uPuqjuwSi+uunjXwkhtHYba5jaa29o5WFrPlqNVPPXRUb7x1GZeszsBPPHBYfc63QB3rd7Dr/+zh93Ha5lgj6x3xfe9Z7dx1Z/X2+/XwBPvH3ZXK/0n9zg5t7zm7kVV39xGUkwEUeGhVDW0uKvcPLsP7ymyOi7UNHp3TS6va2H1juOszi1yV62t219GVUPve031lT9LBAuAA8aYQwAi8gxwCbDLj++pgszFM0ZSXN3EuZNSvW44vsQ4wvj8vGzOn+KdMFbMyABwlxzA6upa09TGzKwEwGqE3vjjZQC894OlRIWHur+ZPnfDom6N3tlJ0dx9xSye3Zjvnsp7QrqT3NsvxBhDaqyDhOgIrl2cw+QRsXx6ViYhIcKYlBivbqznTEhl0ohYfrV6DwvHJJNfYfUeGp0cQ3aS94C9xGhrcSHPEdonMvNnrwNWW0t2UhQPvn3A/dzpmfGwIR+Al7cdY3pmPMU1TYxMiGJGVjyvfnMJr2w7xsPvHXIP7qtvaefGpeP40Qs7qGlqc1d7RHuUmqoaWhmf5qSyvsVdSjhe7V0F1dFheHXHcdYdKOPGpeO8RpZX1LdQ09TGjf/YDMDcUQlsPlrF71/f67PKsaKuhcbWdq9j2wuqueNV6zY0Kima/IoGd/Ua4K5W+9Sskdz9xj4OltaxcGwyz9u90ZparSqr9YcqWDw+hQnpsfxtvVUqvfWF7Swcm0xdcxvOyDASo8OpbGh1l8pcv0PEmgalvK6FiemdX2bAWhK2rcNw3Tlj2XK0kg15lXznn1sZERfJ+h91XwK2P/gzEWQC+R6PC4AzfZy3SES2AceAm40xO7ueICLXAdcBjBo1quthFcTio8N9Vgn15NeXz+zx2CSPP8ivLBnDPWv2M2dUQrfzulYTdC1JuHx2bhZb86tYf6gCEdw9ckSEW1dMcZ/3mTlZ7u30OAc7CuHqhaOYlB7L5WdkExkewufmZbM69zjPbbJuRtlJ3euMQ0LklNpfkmIieOSaedz83DZ22uMhpnj0tvrvziLSYh2s3V/mbnCfnhlPXXMbD79ndVmNCg+lwxiWTkojJdZBTVOb+zqFdmlHmJ+TyNZ8q7vmiLhI8sobOOtXb7LS7hqcX9HA6twiRKyb8f+clcOGw5Xc+I/NFFU3sc+j3WHuqEQ2H61yJyOXsakxHCqtp7y+pduEeitmjKCwspFFY6NYs7uYhOgIspOi+O3lM9l8tNJdbbdsSjoPvXuQvUW1XqvtrbhvLUft6VHW7i/j+r9vcpca1uwuYc1uq1ru7AkpNEdHUFzTxBH7fFcimDYynh2F1aw7UOauanTZYlevfWHBKH60Ygo5t7wG9K7r8anyZyLw1brS9X/pZmC0MaZORFYALwETuj3JmEeARwDmzZunK5YovwgJER7/8jycjnDm5yRyyezMXvdy6km63VZgDN36uvvialvISY7hmkU57v1JMRFeDdNZiT1P3wEwbWSc+6YOMDUjjl09DGJKcTqYkhHHa986m6bWdo5XN7l7EgEcKW9wd/tt80g0rs8WHRHK3VfMpqS2iRhHGClOB4dK690lgq4NyudOTOV4dRO7j8PMrHiKdjVxrLqJR9d2NtB+adFovnb2WHepZ/H4ZCJCQ1idW+Q1GKunNqcZmfEcKq2nsr6FfcW1hNpJckpGHH+86gwAnvn4KKtzi9iaX8UV87I4a3wKi8YlMzbVSV55PVMyYpk7KpGPD1d4ldI8q7L+8MY+anuYoC8mIoz2aONOUmEh4q62mjMqwecAxs7nhjI66cT/xv3Jn91HC4Bsj8dZWN/63YwxNcaYOnt7FRAuIikoFSDnT05nwZgkROS0kwBY3Vb74sr51p+Mq1eTp3SPRNDTDfD5r5/Fyzct5qefmkaMR5WMqx1g+bQR7rEOLp5TckSGhzImJYYUp4PnbljE7juWs3JmBhPSnOQkR3Opx+fJSY7mtoun8s73z2P59BF8yU5crllkXTPUdi0RLJmQ6u5VNcujp5WnC6aO8Kr6SoiO4BNT0njigzw+OlzB5+dZ1+lsH9cJrEQAVlXS+westTKe/tpC/v7VBe5zRnuMBRllv5eIsGJGBt84bzwiwoIxSewpquXbz1g9nVbOzPB6H19JwNXByBkZ5v53HJsSw8Uez3UNXLt2cY7P+JdMSHF/cfjD5zv/vfw1XYU/SwQbgAkiMgYoBK4Evuh5goiMAIqNMUZEFmAlpnI/xqTUgBqZEMVr31ri/iZ4MjOzErwGNXnyTAQ98ZzMb+cdy93VCq5BXFMyrOk8bn5uG5fMHsl3lk3ssUeMq8rrgS/Mob3DdJu0TkT4ypIx3Z7n6rWTbr+uq/1kdHI0o5KicTrC3J/Fs6fV2h8s5ezfvG3H6V1vDnDj0vGEiLBwbBJXLxzNXZfNQER48isL+OG/tntVnczOTiA0RPjwUDlb86v4/oWTvEZJQ+d6G0C39haXBWOsa1DZ0MptF0/lK0vGECpbeHnbMb71iQm8sau423QRF00fwaodRTgdYXz93HFMHhHL6OQYnvm4c8LBaSPj2f+Li6isb+Ev7+d1e9/vX9g5R9dn5mTR2m74wb+2U1rb3GOsp8NvicAY0yYiNwH/xeo++rgxZqeI3GAffwi4HPi6iLQBjcCVRherVcPMtJHxJz+pF3xNwNdbrrUlJo2IJTI8lA9uOZ8Up8PnwL2uRMTnPEU9cXVzTLerhlzVWL+5bKa799elczJxhIW4R347wkLISowiLjKM6Igwkn10lZyeGc+DV83ttv/cialcMS+L+97qnOlzXKqT+TmJvLjFWpOiaw8vsKrhvnjmKP7x0VEmpHVPPAALcpL45WdmcO6kVHcyXTkzg5e3HWPJ+BS+u2wCv3htN39ed5gFY5K4fG6W3ehcRHioICKcP9lqV/EcbR4bGUZ4aIjXPoAzxyRx9+dnu9/LxZU4i2uahlYiAHd1z6ou+x7y2H4AeMCfMSg1XFhTgI/rsXHal49+9Ala2zvITIhifJqTOaOsEsPIBP8NUFo0LpkFB5Lc4yZ+cvEU5o5KcH+7ButGfdP5EzDG8OWzcvjMnEz7ppnmNTajt1xtKynOCFbMyCAhOpyzJ6Sy/lAFs7MTvAaSefrFpdO5/pyxXtVEnkJChC+e6d1B5cJpI9jwf8vcN/EU+/e0kXFcMT+bv9s9iLqOxPYsrbl6UnUdqJbidHRLAoC7fchfDcY6slipIcSzyqA3PKuTXEnA3+blJPHs9Z0TqkVHhPG5edk+zxURfvbpae7H91w555TeM9V9M47njkus2W4/OzeTd/eV8qvPzujxeSLSYxLozfsBRNqlKlfXW1fJrbLBOxHMye68/p4J4K7PzuCV7cd4/0A5cVG+b8mu9hZf01L0B51rSCk15LnWe2jxGEORER/Fs9cvco8o95cVMzIYnRzNV+yGX9c3/8vPyPI6LyRE+PSske6Ge5crF4ziG+eNByAuMhxf4qPCiQgL8dtyp1oiUEoNea5xD1ctHPhxRmlxkbz7/aVej3tq8L/3ytk+5y1yJQDPbrueRISnv3YmmQn+6VKqiUApNeSlxjp6vPkOJj1NXueqEortoUQAcMbo3rcN9ZVWDSmlVIBlJ0Zz09LxXDite++mgaAlAqWUCrCQEOHmC3s/VUq/v3/A3lkppdSgoIlAKaWCnCYCpZQKcpoIlFIqyGkiUEqpIKeJQCmlgpwmAqWUCnKaCJRSKsjJUJv+X0RKgSOn+PQUoOykZwWWxnj6Bnt8oDH2l8Ee42CKb7QxJtXXgSGXCE6HiGw0xswLdBwnojGevsEeH2iM/WWwxzjY43PRqiGllApymgiUUirIBVsieCTQAfSCxnj6Bnt8oDH2l8Ee42CPDwiyNgKllFLdBVuJQCmlVBeaCJRSKsgFTSIQkeUisldEDojILYGOx0VE8kRkh4hsFZGN9r4kEXlDRPbbvxMHMJ7HRaRERHI99vUYj4jcal/TvSJyYQBj/JmIFNrXcauIrAhUjCKSLSJvi8huEdkpIt+29w+a63iCGAfTdYwUkY9FZJsd4+32/kFxHU8Q36C5hr1mjBn2P0AocBAYC0QA24CpgY7Lji0PSOmy7zfALfb2LcCvBzCec4C5QO7J4gGm2tfSAYyxr3FogGL8GXCzj3MHPEYgA5hrb8cC++w4Bs11PEGMg+k6CuC0t8OBj4CFg+U6niC+QXMNe/sTLCWCBcABY8whY0wL8AxwSYBjOpFLgCft7SeBSwfqjY0x7wEVvYznEuAZY0yzMeYwcADrWgcixp4MeIzGmOPGmM32di2wG8hkEF3HE8TYk0DEaIwxdfbDcPvHMEiu4wni60lA/l56I1gSQSaQ7/G4gBP/px9IBnhdRDaJyHX2vnRjzHGw/mCBtIBFd+J4Btt1vUlEtttVR67qgoDGKCI5wBysb4uD8jp2iREG0XUUkVAR2QqUAG8YYwbVdewhPhhE17A3giURiI99g6Xf7GJjzFzgIuBGETkn0AH1wWC6rn8CxgGzgePA7+39AYtRRJzA88B3jDE1JzrVx75AxTiorqMxpt0YMxvIAhaIyPQTnD7gMfYQ36C6hr0RLImgAMj2eJwFHAtQLF6MMcfs3yXAi1hFxWIRyQCwf5cELkI4QTyD5roaY4rtP8oO4FE6i9wBiVFEwrFusE8ZY16wdw+q6+grxsF2HV2MMVXAO8ByBtl17BrfYL2GJxIsiWADMEFExohIBHAl8HKAY0JEYkQk1rUNXADkYsX2P/Zp/wP8OzARuvUUz8vAlSLiEJExwATg4wDE57ohuHwG6zpCAGIUEQEeA3YbY+72ODRormNPMQ6y65gqIgn2dhSwDNjDILmOPcU3mK5hrwW6tXqgfoAVWD0jDgL/F+h47JjGYvUi2AbsdMUFJANvAvvt30kDGNPTWMXZVqxvMF89UTzA/9nXdC9wUQBj/BuwA9iO9QeXEagYgSVYRf7twFb7Z8Vguo4niHEwXceZwBY7llzgNnv/oLiOJ4hv0FzD3v7oFBNKKRXkgqVqSCmlVA80ESilVJDTRKCUUkFOE4FSSgU5TQRKKRXkNBEoNYBE5DwReTXQcSjlSROBUkoFOU0ESvkgIlfbc81vFZGH7cnF6kTk9yKyWUTeFJFU+9zZIrLenmTsRdckYyIyXkTW2PPVbxaRcfbLO0XkXyKyR0Seskf5KhUwmgiU6kJEpgCfx5oQcDbQDlwFxACbjTVJ4LvAT+2n/BX4oTFmJtaIUtf+p4AHjTGzgLOwRkODNdPnd7Dmpx8LLPbzR1LqhMICHYBSg9AngDOADfaX9Sisic06gH/a5/wdeEFE4oEEY8y79v4ngefsOaQyjTEvAhhjmgDs1/vYGFNgP94K5ADr/P6plOqBJgKluhPgSWPMrV47RX7S5bwTzc9youqeZo/tdvTvUAWYVg0p1d2bwOUikgbuNXJHY/29XG6f80VgnTGmGqgUkbPt/dcA7xprbv8CEbnUfg2HiEQP5IdQqrf0m4hSXRhjdonIj7FWjgvBmuX0RqAemCYim4BqrHYEsKZCfsi+0R8CrrX3XwM8LCJ32K/xuQH8GEr1ms4+qlQviUidMcYZ6DiU6m9aNaSUUkFOSwRKKRXktESglFJBThOBUkoFOU0ESikV5DQRKKVUkNNEoJRSQe7/A7kUbS3c0lh8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('chatbot.h5')\n",
    "import json\n",
    "import random\n",
    "intents = json.loads(open('intents.json').read())\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    sent_words = nltk.word_tokenize(sentence)\n",
    "    sent_words = [lemmatizer.lemmatize(word.lower()) for word in sent_words]\n",
    "    return sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(sentence, words, show_details=True):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(sentence, model):\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.30\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def chatbot_response(msg):\n",
    "    ints = predict_class(msg, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hey\n",
      "Bot: Hi there, how can I help?\n",
      "You: good morning\n",
      "Bot: Good to see you again\n",
      "You: AI\\\n",
      "Bot: Sorry, can't understand you\n",
      "You: AI\n",
      "Bot: Please give me more info\n",
      "You: machine learning\n",
      "Bot: Please give me more info\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "resp = []\n",
    "while(flag==True):\n",
    "    try:\n",
    "        res = input('You: ')\n",
    "        if res==\"quit\" or res==\"stop\" or res=='Quit' or res==\"Stop\":\n",
    "            flag=False\n",
    "            print(\"Bot: Okay\")\n",
    "        else:\n",
    "            print('Bot:',chatbot_response(res))\n",
    "    except Exception:\n",
    "        print(\"Bot: Sorry I can't understand\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
